<h1 align="center">ğŸ“Š Media Prediction and Its Cost</h1>
<h3 align="center">ğŸ¯ Predicting Customer Acquisition Cost (CAC) with Machine Learning</h3>

<p align="center">
  <img src="https://img.shields.io/badge/Project-Type%3A%20Academic-orange?style=for-the-badge" />
  <img src="https://img.shields.io/badge/License-MIT-lightgrey?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Model-Built%20with%20Scikit--Learn-blue?style=for-the-badge&logo=scikit-learn" />
</p>

<hr>

<h2>ğŸ“Œ Overview</h2>

<p>
This project was developed as part of the <strong>Applied Machine Learning</strong> course at UT Dallas. 
Our goal was to help a fictional retail chain, <b>Food Mart USA</b>, improve their marketing budget by predicting the <strong>Customer Acquisition Cost (CAC)</strong> across various campaigns and store types.
</p>

<p>
Using a dataset of 60,000 customers sourced from Kaggle, we built regression models to identify cost drivers and recommend optimizations for ROI-focused marketing.
</p>

<hr>

<h2>ğŸ§  Problem Statement</h2>

<p>
Predicting <strong>Customer Acquisition Cost (CAC)</strong> helps businesses allocate their marketing budget efficiently.
We used media campaign data, store attributes, and customer demographics to forecast CAC and optimize resource allocation across Food Mart's marketing channels.
</p>

<hr>

<h2>ğŸ” Dataset</h2>

<ul>
  <li>ğŸ“ <code>media prediction and its cost.csv</code> from Kaggle</li>
  <li>ğŸ‘¥ 60,000 customers</li>
  <li>ğŸ”¢ Variables include: income, promotion type, store size, product preferences, and media exposure</li>
</ul>

<hr>

<h2>ğŸ§ª ML Approach</h2>

<ul>
  <li>ğŸ“Š <strong>EDA</strong>: Data cleaning, visualization, and statistical testing</li>
  <li>ğŸ§¹ <strong>Preprocessing</strong>: One-hot encoding, correlation filtering, feature reduction</li>
  <li>ğŸ“ˆ <strong>Models Used</strong>:
    <ul>
      <li>Linear Regression</li>
      <li>Polynomial Regression with Lasso</li>
      <li>Decision Tree Regressor</li>
      <li><strong>Random Forest Regressor (Best Performer)</strong></li>
    </ul>
  </li>
</ul>

<hr>

<h2>ğŸ“Š Model Evaluation Results</h2>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>RÂ²</th>
      <th>MAE</th>
      <th>RMSE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Linear Regression</td>
      <td>0.37</td>
      <td>19.62</td>
      <td>23.95</td>
    </tr>
    <tr>
      <td>Polynomial Regression (Lasso)</td>
      <td>0.99</td>
      <td>1.88</td>
      <td>3.25</td>
    </tr>
    <tr>
      <td>Decision Tree Regressor</td>
      <td>0.997</td>
      <td>0.08</td>
      <td>1.69</td>
    </tr>
    <tr>
      <td><strong>Random Forest Regressor</strong></td>
      <td><strong>0.998</strong></td>
      <td><strong>0.08</strong></td>
      <td><strong>1.13</strong></td>
    </tr>
  </tbody>
</table>

<p><em>ğŸ‰ Final model (Random Forest) achieved RÂ² = 0.998 and MAE â‰ˆ $0.08 â€” extremely high predictive power!</em></p>

<hr>

<h2>ğŸ“ Folder Structure</h2>

<pre>
media-prediction-cost/
â”œâ”€â”€ AML_Project_Final.ipynb
â”œâ”€â”€ media prediction and its cost.csv
â”œâ”€â”€ Report - Group 7.pdf
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ assets/
    â””â”€â”€ (charts, demo visuals)
</pre>

<hr>

<h2>ğŸ™‹â€â™‚ï¸ Author</h2>

<p>
<strong>Prathamesh Nagraj</strong><br>
ğŸ“§ <a href="mailto:ppnagraj.work@gmail.com">ppnagraj.work@gmail.com</a><br>
ğŸ”— <a href="https://www.linkedin.com/in/prathamesh-nagraj/">LinkedIn Profile</a>
</p>

<hr>

<h2>ğŸ“„ License</h2>

This project is licensed under the <strong>MIT License</strong> â€” feel free to use, fork, or adapt it.

<hr>

<p align="center"><em>â€œLet the data drive the dollars.â€</em></p>
